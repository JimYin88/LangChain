{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04766d96-042d-438b-a7c2-792b1c219189",
   "metadata": {},
   "source": [
    "## CSV Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a86b768-5883-404b-8793-7f028c354635",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import CSVLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dfc20f1-442d-489e-ad1a-5ddda9e0282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader(\"penguins.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df3db5cf-c1b8-461c-8ccd-ff731b68e8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1486503-bd11-4bd4-94a4-dc4bc81363f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species: Adelie\n",
      "island: Torgersen\n",
      "bill_length_mm: 39.1\n",
      "bill_depth_mm: 18.7\n",
      "flipper_length_mm: 181\n",
      "body_mass_g: 3750\n",
      "sex: MALE\n"
     ]
    }
   ],
   "source": [
    "print(data[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab319d2-2602-4b20-b4ff-3b76514faa97",
   "metadata": {},
   "source": [
    "## HTML Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6be60a9-14eb-49ff-8fc5-bcfbeead13b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import BSHTMLLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9d5e03f-4169-4755-8fe4-6be584825033",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = BSHTMLLoader(\"some_website.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "641dd47a-53c8-49ca-a2d7-6daa72be84a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efb988ac-b5a4-4f0a-9b25-f229d67557a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Heading 1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87d8bf2-7869-401a-8234-58c568cf38fb",
   "metadata": {},
   "source": [
    "## PDF Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb08da8b-cb40-45a9-91d4-99c5883fab1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e44d6b8-d1ed-4ba9-9f7e-060d02a08166",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"SomeReport.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "113609ba-251b-4e3d-b37b-564add93e11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0288de75-fd19-4fee-b7f9-1a7634b77a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'producer': 'Skia/PDF m117 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'SomeReport', 'source': 'SomeReport.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Thisisthefirst linePDF.ThisisthesecondlineinthePDF.ThisisthethirdlineinthePDF.')]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f572ff1-3bad-4f69-8414-e076b3cc7e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thisisthefirst linePDF.ThisisthesecondlineinthePDF.ThisisthethirdlineinthePDF.\n"
     ]
    }
   ],
   "source": [
    "print(data[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4ed663-5b1a-4d49-b460-3ee5dad4d462",
   "metadata": {},
   "source": [
    "## Document Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "200f37f9-c03e-4a49-929b-c2be174b46f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import HNLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdb471fe-d637-4e21-9475-57dec2432fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = HNLoader(\"https://news.ycombinator.com/item?id=36697119\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe01fefc-0adf-40e4-bce3-deb3fbe71e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1682adf-14e1-4b50-b087-706561b7a9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "endisneigh on July 12, 2023  \n",
      "             | next [–] \n",
      "\n",
      "I wish the folks who clearly do not like Google would just not use their products instead of spamming every thread about how they will kill the product, true or not.——Anyway,It’s not clear which model they’re using for this. I assume whatever Bard is using, but who knows. This is relevant because depending on the intended experience the latency will matter.Overall it’s not a bad idea, but I do wonder what the monetization path will be for Google. I imagine this will be part of workspace. Perhaps they will add more tiers to include these offerings.I wish they shared a bit about how this will be differentiated from Bard. Is this simply a new front end to Bard? It’s really an open question. I haven’t seen many products that use LLMs that are better than the prompt response UX.The most interesting thing about this blog post is the “source grounding.” I’m curious if there’s actual engineering behind it, or is it prompt tweaking contextualized behind the scenes on a given doc.\n"
     ]
    }
   ],
   "source": [
    "print(data[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47df6fed-834f-43a2-ae5a-1519f9145c6a",
   "metadata": {},
   "source": [
    "### Loading the comment into ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1594dbd-3846-4922-b48b-cf35993a3ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "610c8d14-2766-41a3-bdf4-26ec19a1876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94481ba8-71ce-441e-8963-d0b4a3335dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_prompt = HumanMessagePromptTemplate.from_template(\"Give me a short summary of the following comment: \\n{comment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b903a7cf-87ba-4d21-8d1f-f6178fa62824",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages(messages=[human_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d42115f2-2a29-4006-9843-daa5384e28cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prompt = chat_prompt.format_prompt(comment=data[0].page_content).to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "339ca2eb-5197-4624-9864-a0c420c616c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "40a52f49-e6ae-4b16-8219-f52b797830cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o-mini-2024-07-18\",\n",
    "                   max_tokens=300,\n",
    "                   temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd2ca127-fb17-454f-9040-883aff7ed365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The commenter expresses frustration with individuals who dislike Google and constantly criticize its products instead of not using them. They discuss uncertainty about the model being used for a new Google product, speculating it might be related to Bard, and question its latency and monetization strategy, suggesting it could be integrated into Google Workspace. They also express curiosity about how this new offering will differ from Bard and whether it will improve upon existing large language model (LLM) user experiences. Finally, they highlight the intriguing aspect of \"source grounding\" mentioned in the blog post, questioning the engineering behind it.\n"
     ]
    }
   ],
   "source": [
    "print(model.invoke(model_prompt).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6c8a4e-156e-4065-b7a1-25d832b0a02a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
