{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe79f6b1-50a4-48db-93c0-575c5a6e076a",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f850a85a-f41d-426b-933e-f7f35a552c4d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4407246-3a8c-4d97-ba1b-09b4f6bdc3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI, ChatOpenAI\n",
    "\n",
    "from langchain.memory import (ChatMessageHistory, \n",
    "                              ConversationBufferMemory, \n",
    "                              ConversationBufferWindowMemory,\n",
    "                              ConversationSummaryBufferMemory)\n",
    "\n",
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e948a0-5837-480b-8f34-a94c57c0f982",
   "metadata": {},
   "source": [
    "## Loading Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7bf7d72-0ff0-43a8-853a-89dd472d38b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3748325-b48c-4dc5-9e6b-61f65e9c1918",
   "metadata": {},
   "source": [
    "## Create an instance of Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff80f171-c189-4b0c-aa92-75c3340657bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini-2024-07-18\",\n",
    "                        max_completion_tokens=300,\n",
    "                        temperature=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74b0bfb-a2cf-454f-b1bf-3c74dac878f4",
   "metadata": {},
   "source": [
    "## ChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "985401b2-2d43-41fc-a6a4-73e178e711a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b1cc04b-b85c-4230-9dfe-074a93c3a108",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.add_user_message(\"Hello nice to meet you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37c09d5f-e5c2-4a54-a66c-0ecdd5f7fa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.add_ai_message(\"Nice to meet you!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99ba040a-2608-4c61-8b3a-1074659a8b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content='Hello nice to meet you', additional_kwargs={}, response_metadata={}), AIMessage(content='Nice to meet you!', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acaf67ca-fc7e-4dff-8e1a-a699564fde8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello nice to meet you'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.messages[0].content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22c4790-dfcd-479d-a23d-c6abcf63973f",
   "metadata": {},
   "source": [
    "## ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2af4cb7-7a1c-4b22-b0b9-172bc30f406a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JimYi\\AppData\\Local\\Temp\\ipykernel_28556\\995385594.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "038232e9-e706-4eab-b8dc-c9bd00c547ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JimYi\\AppData\\Local\\Temp\\ipykernel_28556\\1575792625.py:1: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation = ConversationChain(llm=chat_model, memory=memory, verbose=True)\n"
     ]
    }
   ],
   "source": [
    "conversation = ConversationChain(llm=chat_model, memory=memory, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "483ba161-d74a-49fd-bcee-b6137158c036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hello, nice to meet you.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello! It’s great to meet you too! How’s your day going so far?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Hello, nice to meet you.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34a4a328-40ca-43eb-8acb-fd435915fb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello, nice to meet you.\n",
      "AI: Hello! It’s great to meet you too! How’s your day going so far?\n",
      "Human: Tell me an interesting physics fact.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sure! Did you know that light from distant stars can take millions or even billions of years to reach us? For example, the light we see from the Andromeda Galaxy takes about 2.5 million years to travel to Earth. This means that when we look at Andromeda, we’re actually seeing it as it was 2.5 million years ago! Isn’t that mind-blowing? It’s a great reminder of the vastness of the universe and how time and space are interconnected. Do you have a favorite topic in physics?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Tell me an interesting physics fact.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0017c08a-3624-4156-8356-7e1c670a91c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='Hello, nice to meet you.', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello! It’s great to meet you too! How’s your day going so far?', additional_kwargs={}, response_metadata={}), HumanMessage(content='Tell me an interesting physics fact.', additional_kwargs={}, response_metadata={}), AIMessage(content='Sure! Did you know that light from distant stars can take millions or even billions of years to reach us? For example, the light we see from the Andromeda Galaxy takes about 2.5 million years to travel to Earth. This means that when we look at Andromeda, we’re actually seeing it as it was 2.5 million years ago! Isn’t that mind-blowing? It’s a great reminder of the vastness of the universe and how time and space are interconnected. Do you have a favorite topic in physics?', additional_kwargs={}, response_metadata={})]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fda404a-6a83-43e7-be53-2a1317361f87",
   "metadata": {},
   "source": [
    "## Saving and Retrieving Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be8339b0-e429-4f51-a8cf-3887da43fc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "287ecc04-2640-47f6-94a9-0498298d950c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickled_str = pickle.dumps(conversation.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72f457fe-8ff2-4100-83fe-66940e7ef51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./tutorial/output/convo_memory.pkl', 'wb') as f:\n",
    "    f.write(pickled_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ab8c7ed-8286-43f9-a43c-d63aafc7c5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_memory_loaded = open('./tutorial/output/convo_memory.pkl', 'rb').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b8333f0-ee20-4074-8af6-27d0f9eef88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='Hello, nice to meet you.', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello! It’s great to meet you too! How’s your day going so far?', additional_kwargs={}, response_metadata={}), HumanMessage(content='Tell me an interesting physics fact.', additional_kwargs={}, response_metadata={}), AIMessage(content='Sure! Did you know that light from distant stars can take millions or even billions of years to reach us? For example, the light we see from the Andromeda Galaxy takes about 2.5 million years to travel to Earth. This means that when we look at Andromeda, we’re actually seeing it as it was 2.5 million years ago! Isn’t that mind-blowing? It’s a great reminder of the vastness of the universe and how time and space are interconnected. Do you have a favorite topic in physics?', additional_kwargs={}, response_metadata={})]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle.loads(new_memory_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdc388f-960d-462b-b9b8-b2992ec4640b",
   "metadata": {},
   "source": [
    "## ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cab71b9e-5f6d-45fb-8b7c-5c0a2fe680ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JimYi\\AppData\\Local\\Temp\\ipykernel_28556\\597047389.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory2 = ConversationBufferWindowMemory(k=1)\n"
     ]
    }
   ],
   "source": [
    "memory2 = ConversationBufferWindowMemory(k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9900b53-8fed-4516-bd7f-c523b52e16e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation2 = ConversationChain(llm=chat_model, memory=memory2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21005965-228a-4832-9ec8-6296dda5343a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm doing well, thanks for asking. I'm here and ready to chat about anything on your mind. How about you? How's your day going?\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation2.predict(input='Hello, how are you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5698a5c5-1fb0-4ae3-aa40-826fa5ad130d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure! Here’s one for you: Why did the dog sit in the shade? Because he didn’t want to become a hot dog! 😄 Do you have a favorite type of dog?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation2.predict(input='Tell me a joke about dogs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d17fe522-596e-4003-8e1d-d4bf3e25d52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Of course! Here’s a cat joke for you: Why was the cat sitting on the computer? Because it wanted to keep an eye on the mouse! 😸 Do you have a favorite breed of cat?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation2.predict(input='Tell me a joke about cats.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8fce1369-77f3-4106-88e1-2fa30b40251d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Tell me a joke about cats.\\nAI: Of course! Here’s a cat joke for you: Why was the cat sitting on the computer? Because it wanted to keep an eye on the mouse! 😸 Do you have a favorite breed of cat?'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory2.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2734f06-e87e-4eb5-b48c-76f247e2e453",
   "metadata": {},
   "source": [
    "## ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d81f4760-945a-4f5a-9791-db4e674a877b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JimYi\\AppData\\Local\\Temp\\ipykernel_28556\\1667914109.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory3 = ConversationSummaryBufferMemory(llm=chat_model, max_token_limit=100)\n"
     ]
    }
   ],
   "source": [
    "memory3 = ConversationSummaryBufferMemory(llm=chat_model, max_token_limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd4df39f-4722-4e79-9897-481ca3e8a606",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(llm=chat_model, memory=memory3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "538cd30b-2739-4fce-a95d-7a534027bb43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure! Here’s a detailed one-week vacation plan for Los Angeles that covers a mix of iconic attractions, local culture, and leisure activities:\\n\\n**Day 1: Arrival and Santa Monica**\\n- **Morning:** Arrive in Los Angeles and check into your hotel. If you’re staying near Santa Monica, that’s a great starting point!\\n- **Afternoon:** Head to Santa Monica Pier for a stroll and grab lunch at one of the restaurants overlooking the ocean. Try the Pacific Park amusement rides if you’re feeling adventurous.\\n- **Evening:** Walk along the Santa Monica beach and enjoy the sunset. Consider dining at one of the beachfront restaurants, such as The Lobster, known for its seafood and ocean views.\\n\\n**Day 2: Hollywood and Griffith Park**\\n- **Morning:** Start with a visit to the Hollywood Walk of Fame. Don’t forget to take a photo with the iconic TCL Chinese Theatre!\\n- **Afternoon:** Head to Griffith Park. Hike up to Griffith Observatory for great views of the Hollywood sign and the city skyline. Visit the observatory and explore its exhibits.\\n- **Evening:** Catch a live show at the Hollywood Bowl (check their schedule for events) or have dinner at a nearby restaurant like Musso & Frank Grill, a classic Hollywood spot.\\n\\n**Day 3: Downtown LA and Arts District**\\n- **Morning:** Explore the historic Olvera Street and the vibrant Los Angeles Union Station. Enjoy breakfast at a local café.\\n- **Afternoon:**'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Give me one-week vacation plan for Los Angeles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74d57cd9-a2eb-4703-a690-83e0f072e644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure! Here's a detailed one-day trip plan for the Bronx Zoo:\\n\\n**Morning: Arrival and Exploration**\\n\\n- **8:30 AM:** Arrive at the Bronx Zoo. It's best to get there early to beat the crowds and maximize your time. The zoo opens at 10 AM, but you can explore the surrounding area a bit before entering.\\n  \\n- **9:00 AM:** Grab a quick breakfast at the nearby **Café Zoon** located inside the zoo. They offer a variety of breakfast options, including pastries, coffee, and light fare.\\n\\n- **10:00 AM:** Enter the zoo and start your adventure at the **Wild Asia** section, where you can see animals like red pandas, tigers, and elephants. Don’t miss the **Treetop Adventure**, which offers a unique view of the animals from above.\\n\\n**Midday: Animal Encounters and Lunch**\\n\\n- **12:00 PM:** Head to the **African Plains** exhibit. Here you can see giraffes, zebras, and lions in a more open setting. This area is great for photo opportunities!\\n\\n- **1:00 PM:** Break for lunch at the **JungleWorld** café, where you can find Asian-inspired dishes, salads, and kid-friendly options. Alternatively, pack a picnic to enjoy in one of the zoo's designated areas.\\n\\n**Afternoon: More Exhibits and Attractions**\\n\\n- **2:00 PM:** After lunch, visit the **Conservation Hall**\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Give me a one-day trip to the Bronx Zoo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f601382-0c78-4f61-aad1-7f3cc08ab740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human asks the AI for a one-week vacation plan for Los Angeles, and the AI provides a detailed itinerary including Day 1 in Santa Monica, with hotel check-in, a visit to the Santa Monica Pier, and an ocean-view dinner. Day 2 involves exploring Hollywood, including the Walk of Fame and Griffith Park, concluding with a live show at the Hollywood Bowl or dining at Musso & Frank Grill. Day 3 features a visit to Olvera Street and Los Angeles Union Station for breakfast. Additionally, the human requests a one-day trip plan for the Bronx Zoo, which the AI outlines, starting with an early arrival, a breakfast at Café Zoon, and exploration of the Wild Asia section, followed by visits to the African Plains exhibit and lunch at the JungleWorld café.'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory3.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8c284d-b9fd-4482-b43e-7bb9f46e7f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46c97fff-32ed-4054-a9fd-f2507990e0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "# Define a chat model\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini-2024-07-18\",\n",
    "                  max_completion_tokens=300,\n",
    "                  temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0579876f-c653-4656-aee4-889ce898af9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model(state: MessagesState):\n",
    "    response = model.invoke(state[\"messages\"])\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "\n",
    "# Adding memory is straight forward in langgraph!\n",
    "memory = MemorySaver()\n",
    "\n",
    "app = workflow.compile(\n",
    "    checkpointer=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "05d7524f-d4d3-4e5f-90d9-6d7be68de509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm bob\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Bob! How can I assist you today?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what was my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Bob! How can I help you, Bob?\n"
     ]
    }
   ],
   "source": [
    "thread_id = uuid.uuid4()\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "\n",
    "input_message = HumanMessage(content=\"hi! I'm bob\")\n",
    "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "# Here, let's confirm that the AI remembers our name!\n",
    "input_message = HumanMessage(content=\"what was my name?\")\n",
    "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f6bdab22-2990-4ed4-8833-a9ba72bd8b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
