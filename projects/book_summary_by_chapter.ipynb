{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04aa264a-3ff2-4632-b17a-25bfb077cd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Models\n",
    "from langchain_openai import OpenAI, ChatOpenAI\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_ollama import ChatOllama\n",
    "import ollama\n",
    "\n",
    "# from ollama import chat\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# OutputParsers\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "# Gradio frontend\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34d883bc-cb05-418a-8751-f705ec807c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5594ade8-df62-4d31-a75b-d892c76a2817",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_filepath = {\"A Christmas Carol\": '.\\\\data\\\\A_Christmas_Carol.txt',\n",
    "                 \"Moby Dick\": '.\\\\data\\\\Moby_Dick.txt', \n",
    "                 \"Macbeth\": '.\\\\data\\\\Macbeth.txt',\n",
    "                 \"Silas Marner\": '.\\\\data\\\\Silas_Marner.txt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ad2a79b-c3e5-4e2a-92ad-6d86c3819b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def book_chapter_summary(llm='llama3.2', book_title=\"Moby Dick\", chapter_num=1):\n",
    "    \n",
    "    filepath = book_filepath[book_title]\n",
    "    \n",
    "    with open(file=filepath, mode='r') as file:\n",
    "        f = file.read()\n",
    "\n",
    "    f_lines = f.split('\\n')\n",
    "    title = f_lines[0]\n",
    "    author = f_lines[2].split('By ')[-1]\n",
    "    chapters = f.split('[divider]')[1:]\n",
    "\n",
    "    num_chapters = len(chapters)\n",
    "    \n",
    "    if chapter_num > num_chapters:\n",
    "        chapter_selected = num_chapters\n",
    "    else:\n",
    "        chapter_selected = chapter_num\n",
    "        \n",
    "    chapter = chapters[chapter_selected - 1]\n",
    "    \n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    Provide a summary of the following text, at most 200 words. Answer must be based only on the text given. \n",
    "    context: {chapter}\n",
    "    \"\"\")\n",
    "\n",
    "    if llm == 'gpt-4o-mini':\n",
    "        chat_model = ChatOpenAI(model=\"gpt-4o-mini-2024-07-18\",\n",
    "                                max_completion_tokens=256,\n",
    "                                temperature=0.7)\n",
    "    elif llm == 'llama3.2':\n",
    "        chat_model = OllamaLLM(model=\"llama3.2\",\n",
    "                               num_ctx = 8192, \n",
    "                               num_predict = 256,\n",
    "                               temperature = 0.7)\n",
    "\n",
    "    chat_chain = prompt | chat_model | StrOutputParser()\n",
    "\n",
    "    response = chat_chain.invoke({\"chapter\": chapters[chapter_num - 1]})\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37a3994e-5448-4b9a-9a0c-fdf3685478a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "interface = gr.Interface(fn = book_chapter_summary,\n",
    "                         inputs=[gr.Dropdown(choices=['gpt-4o-mini', 'llama3.2'],\n",
    "                                             value='llama3.2',\n",
    "                                             multiselect=False,\n",
    "                                             label=\"LLM Model\"),\n",
    "                                 gr.Dropdown(choices=['A Christmas Carol', \n",
    "                                                      'Moby Dick',\n",
    "                                                      'Macbeth',\n",
    "                                                      'Silas Marner'],\n",
    "                                             value='Moby Dick',\n",
    "                                             multiselect=False,\n",
    "                                     label=\"Title of the Book\"), \n",
    "                                 gr.Number(label=\"Chapter Number\", \n",
    "                                           value=1,\n",
    "                                           minimum=1)],\n",
    "                         outputs=[gr.Text(label=\"Summary\")],\n",
    "                         flagging_mode=\"never\"\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb4d0897-fab4-4070-9a6f-f1ec9d55f73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7869\n",
      "* Running on public URL: https://f9f30aad58037211fd.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://f9f30aad58037211fd.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8117202c-9a9b-4489-809c-0b97bda3acb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
