{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a22ef8e-b0f2-4702-a01e-69269e0bc67b",
   "metadata": {},
   "source": [
    "# RAG Retrieval System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeb9880-a62b-4e25-914f-1623d7ef77a9",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2069995c-fdeb-4259-a09b-93b16fe894e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "os.environ['USER_AGENT'] = 'JimYin88'\n",
    "\n",
    "# LLM Models\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Templates\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Document Loaders\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "# from langchain_community.document_loaders import WebBaseLoader\n",
    "# from langchain.document_loaders import BSHTMLLoader\n",
    "# from langchain_community.document_loaders import UnstructuredRTFLoader\n",
    "\n",
    "# Document Splitters\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Embeddings\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Vector Stores\n",
    "from langchain_chroma import Chroma\n",
    "# from langchain_community.vectorstores.faiss import FAISS\n",
    "\n",
    "# LangChain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "# OutputParsers\n",
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2968155-a8ff-4e3f-bb86-250928b2b4ca",
   "metadata": {},
   "source": [
    "## Loading Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "899ef1fd-ab65-4ac6-b214-0f289e7cba3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acabcb0d-4da7-4f46-b903-dfa4f645d2fc",
   "metadata": {},
   "source": [
    "## Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f2e8d9f-d41d-48a7-8629-3bbcc2e89100",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = Docx2txtLoader(\".\\\\data\\\\JimYin-Resume.docx\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e85b26e-f48d-4558-8fa2-8d579aa0e56d",
   "metadata": {},
   "source": [
    "## Split documents into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc71da05-9ba8-4549-81a9-7e930538b19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = TokenTextSplitter(chunk_size=400, chunk_overlap=20)\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=20)\n",
    "\n",
    "splitDocs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2b4e9b-3b29-40f9-83cb-2bc88b140e66",
   "metadata": {},
   "source": [
    "## Embedding and Vector Store Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f556e0fd-909c-4c5e-90c7-1b3bef0f2024",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "310f39e9-c2f0-41fc-9a3a-88eff8d79b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_documents(documents=splitDocs, \n",
    "                           embedding=embedding_function, \n",
    "                           collection_name=\"Resume\",\n",
    "                           persist_directory=\"./resume\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae16be2-2c7a-498c-8041-3d6021f82bb7",
   "metadata": {},
   "source": [
    "## ChromaDB methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00951a34-7fb3-442b-8733-eff193ea50c9",
   "metadata": {},
   "source": [
    "### Adding Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d3c7cea-d9c5-4cbe-a566-5a9d9865d6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"}\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98c45afb-d1c5-4ed8-9942-50e95f19ebd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8ec35247-d014-4403-a37f-53080ae0c268',\n",
       " '6cbc4b0c-5250-44d1-a946-6867002c9f46']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.add_documents(documents=[document_1, document_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e50c63-fcbb-4db3-af29-549deccd8359",
   "metadata": {},
   "source": [
    "### Viewing Documents in Chroma DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a333c21-a64b-42c0-9c90-d08e271ec3be",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['3cf3dd25-ac8c-4571-ba45-58cd8b42920d',\n",
       "  'fc383c02-df17-4d79-9e76-a2f0d32c2bae',\n",
       "  'f647d286-bff9-416d-bdac-1a67934c6eba',\n",
       "  '124caf9e-6a81-41f3-8dd9-dbc265babdec',\n",
       "  '8ec35247-d014-4403-a37f-53080ae0c268',\n",
       "  '6cbc4b0c-5250-44d1-a946-6867002c9f46'],\n",
       " 'embeddings': None,\n",
       " 'documents': ['Jim C. Yin\\n\\n101 Darling Ave.\\n\\nBloomfield, NJ 07003\\n\\n Cell (626) 675-1990 • jimyin88@gmail.com\\n\\n\\n\\n\\n\\nSUMMARY\\tHighly skilled data scientist with extensive expertise in the financial markets, possessing more than 20 years of experience in data science and finance.\\n\\n\\t\\t\\n\\nEXPERIENCE\\n\\n\\n\\n\\t\\t\\t1/2023 – 9/2024\\tPrudential Financial, Inc.\\tNewark, NJ\\n\\n\\t\\t\\t\\t\\tSenior Data Scientist\\n\\n\\t\\t\\t• \\tDeveloped various software programs to assist clients in retirement planning, such as a Monte Carlo simulation that accurately projects their life savings and recommends optimal asset allocations based on factors including risk tolerance.\\n\\n\\t\\t\\t• \\tConducted thorough analyses of annuity purchase applications to identify and address potential issues, utilizing similarity searches on advisors with comparable characteristics. Contributed to cost savings for the company by reducing the number of \"Not In Good Order\" incidents.\\n\\n\\t\\t\\t• \\tProposed multiple generative AI projects utilizing LLMs such as OpenAI, aimed at increasing data accuracy, improving model predictability, and streamlining operations. Validated business use cases for these projects by developing prototypes using the LangChain module.\\n\\n\\t\\t\\t\\n\\n\\t\\t\\t9/2015 – 4/2019\\tArgus Information and Advisory Services\\tWhite Plains, NY\\n\\n\\t\\t\\t\\t\\tManager/Data Scientist\\n\\n\\t\\t\\t• \\tWrote complex SQL queries analyzing billions of credit card transactions to help banks, credit card issuers, and merchants better understand their customers and markets. Conducted exploratory data analyses and performed statistical analysis on customer segmentation to forecast consumer spending trends. \\n\\n\\t\\t\\t• \\tData wrangling fuzzy data using SQL and python to de-dupe store names and locations, thus improving data accuracy.\\n\\n\\t\\t\\t• \\t',\n",
       "  \"-dupe store names and locations, thus improving data accuracy.\\n\\n\\t\\t\\t• \\tAutomated and streamlined query operations, resulting in quicker processing time. Developed analytical tools for data validation based on key performance indicators.\\n\\n\\t\\t\\t• \\tCreated Excel pivot tables and Tableau dashboards to display summary results, enabling companies to make critical business decisions.\\n\\n\\t\\t\\t\\n\\n\\t\\t\\t8/2006 – 4/2014\\tS&P Capital IQ\\tNew York, NY\\n\\n\\t\\t\\t\\t\\tIndustry Analyst\\n\\n\\tCovered companies in computer hardware/software, IT services, video games, restaurant, and household durables industries. Developed detailed financial models, projecting future incomes and cash flows based on fundamental analysis, macroeconomics factors, meetings with management, and industry data. Conducted proprietary research, allowing me to make timely sector calls against prevailing market views.\\n\\n\\n\\nWrote research notes and stock reports. Published biannual industry surveys on the computer data storage, restaurant, and household durables industries, highlighting both the current environment and long-term secular trends.\\n\\n\\n\\nSelected as a member of S&P portfolio committee based on superior stock picking performance and broad knowledge of the equity market. Evaluated and recommended equities for specific model portfolios, helping most of the portfolios to significantly outperform their respective benchmarks.\\n\\n\\n\\nAppeared on CNBC, Bloomberg TV, Fox Business, Nightly Business Report, Reuters, and BNN, and quoted numerous times on The Wall Street Journal and other printed media discussing my views about my companies' latest developments.\\n\\n\\n\\n\\t\\t\\n\\n\\t\\t4/2004 – 5/2006\\tEKN Financial Services\\tNew York, NY\\n\\n\\t\\t\\t\\t\\tDirector of Research\\n\\nSupervised other analysts, reviewed their work, and oversaw regulatory compliance issues. Covered companies in computer software and IT services. Talked to management on a regular basis. Organized and participated on companies\",\n",
       "  \" software and IT services. Talked to management on a regular basis. Organized and participated on companies' road shows.\\n\\n\\n\\n\\t\\t2/2001 – 10/2002\\tBrean Capital, LLC\\tNew York, NY\\n\\n\\t\\t\\t\\t\\tSenior Analyst\\n\\n\\tCovered companies in Internet, computer software, and IT services sectors. Evaluated public and private companies with potential funding needs.\\n\\n\\n\\n\\t\\t\\t1/2000 – 12/2000\\tYin Investments\\tNew York, NY\\n\\n\\t\\t\\t\\t\\tPortfolio Manager\\n\\nManaged a hedge fund with investments that focused on Internet and technology companies.\\n\\n\\n\\nEDUCATION\\t\\n\\n\\n\\n\\t\\t\\t\\t\\tThe University of Chicago - Booth School of Business\\n\\n\\t\\t\\t\\t\\tMBA, Finance and Accounting\\n\\n\\n\\n\\t\\t\\t\\t\\tUniversity of California, Berkeley\\n\\n\\t\\t\\t\\t\\tPh.D., Chemical Engineering\\n\\n\\n\\n\\t\\t\\t\\t\\tMassachusetts Institute of Technology\\n\\n\\t\\t\\t\\t\\tS.B., Chemical Engineering\\n\\n\\n\\n\\tSKILLS\\t•\\tProficiency in Python programming with advanced knowledge in modules such as numpy, pandas, scikit-learn, seaborn, and matplotlib.\\n\\n\\t\\t\\t•\\tSkilled in utilizing programming library commonly used in Generative AI, specifically TensorFlow and LangChain. \\n\\n\\t\\t\\t•\\tSolid understanding of advanced machine learning algorithms.\\n\\n\\t\\t\\t•\\tProficient in Natural Language Processing (NLP) techniques using key Python modules including SpaCy. \\n\\n\\t\\t\\t•\\tExpert SQL skills (Microsoft SQL Server, PostgreSQL).\\n\\n\\t\\t\\t•\\tExtensive knowledge of core AWS services such as EC2, S3, and SageMaker.\\n\\n\\t\\t\\t•\\tExperience with Tableau, Plotly, Dash, Streamlit, and other data visualization software.\\n\\n\\t\\t\\t•\\tWorking knowledge of Linux command\",\n",
       "  ' Streamlit, and other data visualization software.\\n\\n\\t\\t\\t•\\tWorking knowledge of Linux command line, git, and GitHub.\\n\\n\\t\\t\\t•\\tStrong understanding of probability and statistics.\\n\\n\\t\\t\\t•\\tProficient in working within an agile environment, utilizing tools such as JIRA to effectively collaborate and track project progress.\\n\\n\\t\\t\\t•\\tDeep domain expertise in securities analysis and equity valuation such as developing financial models with projections of incomes, cash flows, and balance sheets.\\n\\n\\t\\t\\t•\\tExcellent oral, written, and presentation communication skills.\\n\\n\\t\\t\\n\\n\\t\\tCERTIFICATES \\t•\\tCFA Charter Member',\n",
       "  'I had chocolate chip pancakes and scrambled eggs for breakfast this morning.',\n",
       "  'The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.'],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [{'source': '.\\\\data\\\\JimYin-Resume.docx'},\n",
       "  {'source': '.\\\\data\\\\JimYin-Resume.docx'},\n",
       "  {'source': '.\\\\data\\\\JimYin-Resume.docx'},\n",
       "  {'source': '.\\\\data\\\\JimYin-Resume.docx'},\n",
       "  {'source': 'tweet'},\n",
       "  {'source': 'news'}],\n",
       " 'included': [<IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1261857d-4434-43e1-a961-987c6c0229e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='8ec35247-d014-4403-a37f-53080ae0c268', metadata={'source': 'tweet'}, page_content='I had chocolate chip pancakes and scrambled eggs for breakfast this morning.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.get_by_ids(['8ec35247-d014-4403-a37f-53080ae0c268'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bbf720-e08c-4be1-98fa-d8190f51a6c4",
   "metadata": {},
   "source": [
    "### Updating Documents in Chroma DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "839e8cf4-2000-4ea1-a60c-6abd958d5748",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_document_1 = Document(\n",
    "    page_content=\"I had chocolate chip pancakes and fried eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=1,\n",
    ")\n",
    "\n",
    "updated_document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is sunny and warm, with a high of 82 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=2,\n",
    ")\n",
    "\n",
    "db.update_document(document_id='8ec35247-d014-4403-a37f-53080ae0c268', document=updated_document_1)\n",
    "\n",
    "# You can also update multiple documents at once\n",
    "# vector_store.update_documents(ids=uuids[:2], documents=[updated_document_1, updated_document_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2d7b4cc-5056-41c5-ac3a-ee73d6f0ee5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I had chocolate chip pancakes and fried eggs for breakfast this morning.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.get()['documents'][-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5456a6-4f6d-4496-9ea5-3c75e1c1af53",
   "metadata": {},
   "source": [
    "### Deleting Documents from Chroma DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aad86e90-c4d4-4719-9056-93da32a9b626",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.delete(ids=['8ec35247-d014-4403-a37f-53080ae0c268',\n",
    "               '6cbc4b0c-5250-44d1-a946-6867002c9f46'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a16148c-6807-44fc-9499-307b935a0e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['3cf3dd25-ac8c-4571-ba45-58cd8b42920d',\n",
       "  'fc383c02-df17-4d79-9e76-a2f0d32c2bae',\n",
       "  'f647d286-bff9-416d-bdac-1a67934c6eba',\n",
       "  '124caf9e-6a81-41f3-8dd9-dbc265babdec'],\n",
       " 'embeddings': None,\n",
       " 'documents': ['Jim C. Yin\\n\\n101 Darling Ave.\\n\\nBloomfield, NJ 07003\\n\\n Cell (626) 675-1990 • jimyin88@gmail.com\\n\\n\\n\\n\\n\\nSUMMARY\\tHighly skilled data scientist with extensive expertise in the financial markets, possessing more than 20 years of experience in data science and finance.\\n\\n\\t\\t\\n\\nEXPERIENCE\\n\\n\\n\\n\\t\\t\\t1/2023 – 9/2024\\tPrudential Financial, Inc.\\tNewark, NJ\\n\\n\\t\\t\\t\\t\\tSenior Data Scientist\\n\\n\\t\\t\\t• \\tDeveloped various software programs to assist clients in retirement planning, such as a Monte Carlo simulation that accurately projects their life savings and recommends optimal asset allocations based on factors including risk tolerance.\\n\\n\\t\\t\\t• \\tConducted thorough analyses of annuity purchase applications to identify and address potential issues, utilizing similarity searches on advisors with comparable characteristics. Contributed to cost savings for the company by reducing the number of \"Not In Good Order\" incidents.\\n\\n\\t\\t\\t• \\tProposed multiple generative AI projects utilizing LLMs such as OpenAI, aimed at increasing data accuracy, improving model predictability, and streamlining operations. Validated business use cases for these projects by developing prototypes using the LangChain module.\\n\\n\\t\\t\\t\\n\\n\\t\\t\\t9/2015 – 4/2019\\tArgus Information and Advisory Services\\tWhite Plains, NY\\n\\n\\t\\t\\t\\t\\tManager/Data Scientist\\n\\n\\t\\t\\t• \\tWrote complex SQL queries analyzing billions of credit card transactions to help banks, credit card issuers, and merchants better understand their customers and markets. Conducted exploratory data analyses and performed statistical analysis on customer segmentation to forecast consumer spending trends. \\n\\n\\t\\t\\t• \\tData wrangling fuzzy data using SQL and python to de-dupe store names and locations, thus improving data accuracy.\\n\\n\\t\\t\\t• \\t',\n",
       "  \"-dupe store names and locations, thus improving data accuracy.\\n\\n\\t\\t\\t• \\tAutomated and streamlined query operations, resulting in quicker processing time. Developed analytical tools for data validation based on key performance indicators.\\n\\n\\t\\t\\t• \\tCreated Excel pivot tables and Tableau dashboards to display summary results, enabling companies to make critical business decisions.\\n\\n\\t\\t\\t\\n\\n\\t\\t\\t8/2006 – 4/2014\\tS&P Capital IQ\\tNew York, NY\\n\\n\\t\\t\\t\\t\\tIndustry Analyst\\n\\n\\tCovered companies in computer hardware/software, IT services, video games, restaurant, and household durables industries. Developed detailed financial models, projecting future incomes and cash flows based on fundamental analysis, macroeconomics factors, meetings with management, and industry data. Conducted proprietary research, allowing me to make timely sector calls against prevailing market views.\\n\\n\\n\\nWrote research notes and stock reports. Published biannual industry surveys on the computer data storage, restaurant, and household durables industries, highlighting both the current environment and long-term secular trends.\\n\\n\\n\\nSelected as a member of S&P portfolio committee based on superior stock picking performance and broad knowledge of the equity market. Evaluated and recommended equities for specific model portfolios, helping most of the portfolios to significantly outperform their respective benchmarks.\\n\\n\\n\\nAppeared on CNBC, Bloomberg TV, Fox Business, Nightly Business Report, Reuters, and BNN, and quoted numerous times on The Wall Street Journal and other printed media discussing my views about my companies' latest developments.\\n\\n\\n\\n\\t\\t\\n\\n\\t\\t4/2004 – 5/2006\\tEKN Financial Services\\tNew York, NY\\n\\n\\t\\t\\t\\t\\tDirector of Research\\n\\nSupervised other analysts, reviewed their work, and oversaw regulatory compliance issues. Covered companies in computer software and IT services. Talked to management on a regular basis. Organized and participated on companies\",\n",
       "  \" software and IT services. Talked to management on a regular basis. Organized and participated on companies' road shows.\\n\\n\\n\\n\\t\\t2/2001 – 10/2002\\tBrean Capital, LLC\\tNew York, NY\\n\\n\\t\\t\\t\\t\\tSenior Analyst\\n\\n\\tCovered companies in Internet, computer software, and IT services sectors. Evaluated public and private companies with potential funding needs.\\n\\n\\n\\n\\t\\t\\t1/2000 – 12/2000\\tYin Investments\\tNew York, NY\\n\\n\\t\\t\\t\\t\\tPortfolio Manager\\n\\nManaged a hedge fund with investments that focused on Internet and technology companies.\\n\\n\\n\\nEDUCATION\\t\\n\\n\\n\\n\\t\\t\\t\\t\\tThe University of Chicago - Booth School of Business\\n\\n\\t\\t\\t\\t\\tMBA, Finance and Accounting\\n\\n\\n\\n\\t\\t\\t\\t\\tUniversity of California, Berkeley\\n\\n\\t\\t\\t\\t\\tPh.D., Chemical Engineering\\n\\n\\n\\n\\t\\t\\t\\t\\tMassachusetts Institute of Technology\\n\\n\\t\\t\\t\\t\\tS.B., Chemical Engineering\\n\\n\\n\\n\\tSKILLS\\t•\\tProficiency in Python programming with advanced knowledge in modules such as numpy, pandas, scikit-learn, seaborn, and matplotlib.\\n\\n\\t\\t\\t•\\tSkilled in utilizing programming library commonly used in Generative AI, specifically TensorFlow and LangChain. \\n\\n\\t\\t\\t•\\tSolid understanding of advanced machine learning algorithms.\\n\\n\\t\\t\\t•\\tProficient in Natural Language Processing (NLP) techniques using key Python modules including SpaCy. \\n\\n\\t\\t\\t•\\tExpert SQL skills (Microsoft SQL Server, PostgreSQL).\\n\\n\\t\\t\\t•\\tExtensive knowledge of core AWS services such as EC2, S3, and SageMaker.\\n\\n\\t\\t\\t•\\tExperience with Tableau, Plotly, Dash, Streamlit, and other data visualization software.\\n\\n\\t\\t\\t•\\tWorking knowledge of Linux command\",\n",
       "  ' Streamlit, and other data visualization software.\\n\\n\\t\\t\\t•\\tWorking knowledge of Linux command line, git, and GitHub.\\n\\n\\t\\t\\t•\\tStrong understanding of probability and statistics.\\n\\n\\t\\t\\t•\\tProficient in working within an agile environment, utilizing tools such as JIRA to effectively collaborate and track project progress.\\n\\n\\t\\t\\t•\\tDeep domain expertise in securities analysis and equity valuation such as developing financial models with projections of incomes, cash flows, and balance sheets.\\n\\n\\t\\t\\t•\\tExcellent oral, written, and presentation communication skills.\\n\\n\\t\\t\\n\\n\\t\\tCERTIFICATES \\t•\\tCFA Charter Member'],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [{'source': '.\\\\data\\\\JimYin-Resume.docx'},\n",
       "  {'source': '.\\\\data\\\\JimYin-Resume.docx'},\n",
       "  {'source': '.\\\\data\\\\JimYin-Resume.docx'},\n",
       "  {'source': '.\\\\data\\\\JimYin-Resume.docx'}],\n",
       " 'included': [<IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8411971e-4bb3-4b3c-a835-01e79d978cb9",
   "metadata": {},
   "source": [
    "### Loading and Connecting an existing Chroma DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c8ace22-bb7b-4ee8-a288-2223fc68da63",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_new_connection = Chroma(collection_name=\"SEC_filings\",\n",
    "                           embedding_function=embedding_function,\n",
    "                           persist_directory=\"./sec_filings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b84dd82-4ec2-4e4b-8ab8-f6d51b42c2c9",
   "metadata": {},
   "source": [
    "## Retrieving Most Relevant Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edef016e-42ac-4ce7-b0f3-761d8f204ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What was Jim C. Yin last job title?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b4a2548-6b17-4f34-8c3a-061e94446f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_docs = db.similarity_search(query = question, \n",
    "                                    k = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f4fef4d-1cb8-485b-88c6-5f64f8c4fa20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='3cf3dd25-ac8c-4571-ba45-58cd8b42920d', metadata={'source': '.\\\\data\\\\JimYin-Resume.docx'}, page_content='Jim C. Yin\\n\\n101 Darling Ave.\\n\\nBloomfield, NJ 07003\\n\\n Cell (626) 675-1990 • jimyin88@gmail.com\\n\\n\\n\\n\\n\\nSUMMARY\\tHighly skilled data scientist with extensive expertise in the financial markets, possessing more than 20 years of experience in data science and finance.\\n\\n\\t\\t\\n\\nEXPERIENCE\\n\\n\\n\\n\\t\\t\\t1/2023 – 9/2024\\tPrudential Financial, Inc.\\tNewark, NJ\\n\\n\\t\\t\\t\\t\\tSenior Data Scientist\\n\\n\\t\\t\\t• \\tDeveloped various software programs to assist clients in retirement planning, such as a Monte Carlo simulation that accurately projects their life savings and recommends optimal asset allocations based on factors including risk tolerance.\\n\\n\\t\\t\\t• \\tConducted thorough analyses of annuity purchase applications to identify and address potential issues, utilizing similarity searches on advisors with comparable characteristics. Contributed to cost savings for the company by reducing the number of \"Not In Good Order\" incidents.\\n\\n\\t\\t\\t• \\tProposed multiple generative AI projects utilizing LLMs such as OpenAI, aimed at increasing data accuracy, improving model predictability, and streamlining operations. Validated business use cases for these projects by developing prototypes using the LangChain module.\\n\\n\\t\\t\\t\\n\\n\\t\\t\\t9/2015 – 4/2019\\tArgus Information and Advisory Services\\tWhite Plains, NY\\n\\n\\t\\t\\t\\t\\tManager/Data Scientist\\n\\n\\t\\t\\t• \\tWrote complex SQL queries analyzing billions of credit card transactions to help banks, credit card issuers, and merchants better understand their customers and markets. Conducted exploratory data analyses and performed statistical analysis on customer segmentation to forecast consumer spending trends. \\n\\n\\t\\t\\t• \\tData wrangling fuzzy data using SQL and python to de-dupe store names and locations, thus improving data accuracy.\\n\\n\\t\\t\\t• \\t'),\n",
       " Document(id='f647d286-bff9-416d-bdac-1a67934c6eba', metadata={'source': '.\\\\data\\\\JimYin-Resume.docx'}, page_content=\" software and IT services. Talked to management on a regular basis. Organized and participated on companies' road shows.\\n\\n\\n\\n\\t\\t2/2001 – 10/2002\\tBrean Capital, LLC\\tNew York, NY\\n\\n\\t\\t\\t\\t\\tSenior Analyst\\n\\n\\tCovered companies in Internet, computer software, and IT services sectors. Evaluated public and private companies with potential funding needs.\\n\\n\\n\\n\\t\\t\\t1/2000 – 12/2000\\tYin Investments\\tNew York, NY\\n\\n\\t\\t\\t\\t\\tPortfolio Manager\\n\\nManaged a hedge fund with investments that focused on Internet and technology companies.\\n\\n\\n\\nEDUCATION\\t\\n\\n\\n\\n\\t\\t\\t\\t\\tThe University of Chicago - Booth School of Business\\n\\n\\t\\t\\t\\t\\tMBA, Finance and Accounting\\n\\n\\n\\n\\t\\t\\t\\t\\tUniversity of California, Berkeley\\n\\n\\t\\t\\t\\t\\tPh.D., Chemical Engineering\\n\\n\\n\\n\\t\\t\\t\\t\\tMassachusetts Institute of Technology\\n\\n\\t\\t\\t\\t\\tS.B., Chemical Engineering\\n\\n\\n\\n\\tSKILLS\\t•\\tProficiency in Python programming with advanced knowledge in modules such as numpy, pandas, scikit-learn, seaborn, and matplotlib.\\n\\n\\t\\t\\t•\\tSkilled in utilizing programming library commonly used in Generative AI, specifically TensorFlow and LangChain. \\n\\n\\t\\t\\t•\\tSolid understanding of advanced machine learning algorithms.\\n\\n\\t\\t\\t•\\tProficient in Natural Language Processing (NLP) techniques using key Python modules including SpaCy. \\n\\n\\t\\t\\t•\\tExpert SQL skills (Microsoft SQL Server, PostgreSQL).\\n\\n\\t\\t\\t•\\tExtensive knowledge of core AWS services such as EC2, S3, and SageMaker.\\n\\n\\t\\t\\t•\\tExperience with Tableau, Plotly, Dash, Streamlit, and other data visualization software.\\n\\n\\t\\t\\t•\\tWorking knowledge of Linux command\")]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa226d75-8f16-436d-b948-3e1b92c66b2a",
   "metadata": {},
   "source": [
    "## Injecting the documents into the prompt context window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa590037-f0f3-44c6-899d-19ca15cc7c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    Answer the user's question.\n",
    "    Context: {context}\n",
    "    Question: {input}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afba4bc-a0bb-454a-9230-89ef22fa80a0",
   "metadata": {},
   "source": [
    "## Instantiate LLM model and Running the Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4deb00e-0853-4256-a4ec-1321f39203a2",
   "metadata": {},
   "source": [
    "### Using ChatGPT 4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f38fb42-bd8a-4c4f-8af5-f3c46bc336fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini-2024-07-18\",\n",
    "                        max_completion_tokens=1028,\n",
    "                        temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b096b0a1-a201-49b2-8ee9-aff370191744",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | chat_model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "faee17b5-dce3-450a-ae1c-e3a048b58bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jim C. Yin's last job title was Senior Data Scientist at Prudential Financial, Inc.\n"
     ]
    }
   ],
   "source": [
    "response1 = chain.invoke({\"context\": similar_docs,\n",
    "                          \"input\": question})\n",
    "\n",
    "print(response1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021a1ac2-1358-4da2-a37d-466ff4f46bab",
   "metadata": {},
   "source": [
    "### Using llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6be029e9-7f4c-4af0-b33b-3b22c4f4abda",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_model = OllamaLLM(model=\"llama3.2\", \n",
    "               num_ctx = 4096, \n",
    "               num_predict = 256,\n",
    "               temperature = 0.7,\n",
    "               system = 'You are a helpful assistant.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2c10f88-f997-40d8-aa97-1ab14dc23ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_chain = prompt | ollama_model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "293ed20f-b940-44b4-9740-8277231b34c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jim C. Yin's last job title was Senior Data Scientist at Prudential Financial, Inc., a position he held from January 2023 to September 2024.\n"
     ]
    }
   ],
   "source": [
    "response2 = ollama_chain.invoke({\"context\": similar_docs,\n",
    "                                 \"input\": question})\n",
    "\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ca0d50-eb7c-4f9a-8c37-ae5df7d9a6dd",
   "metadata": {},
   "source": [
    "## Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2e4322f-d056-4596-b664-74fb62b1894b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_retrieval_question(question):\n",
    "\n",
    "    db_new_connection = Chroma(collection_name=\"Resume\",\n",
    "                           embedding_function=embedding_function,\n",
    "                           persist_directory=\"./resume\")\n",
    "\n",
    "    similar_docs = db.similarity_search(query = question,\n",
    "                                        k = 2)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    Answer the user's question.\n",
    "    Context: {context}\n",
    "    Question: {input}\n",
    "    \"\"\")\n",
    "\n",
    "    ollama_model = OllamaLLM(model=\"llama3.2\",\n",
    "                             num_ctx = 4096, \n",
    "                             num_predict = 256,\n",
    "                             temperature = 0.7,\n",
    "                             system = 'You are a helpful assistant.')\n",
    "\n",
    "    ollama_chain = prompt | ollama_model | StrOutputParser()\n",
    "\n",
    "    response2 = ollama_chain.invoke({\"context\": similar_docs,\n",
    "                                 \"input\": question})\n",
    "\n",
    "    return response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83a91be2-79a6-408a-b5b3-fb993b19cb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jim Yin's last job title mentioned in his resume is Senior Data Scientist at Prudential Financial, Inc. from 1/2023 to 9/2024.\n"
     ]
    }
   ],
   "source": [
    "print(rag_retrieval_question(\"What was Jim Yin's last job title?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cbeb25cf-ddd8-46ea-86e3-87a8042e2dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d815e661-0cca-462a-85d4-d1d417680725",
   "metadata": {},
   "outputs": [],
   "source": [
    "interface = gr.Interface(fn = rag_retrieval_question,\n",
    "                         inputs=[gr.Text(label=\"Question\")],\n",
    "                         outputs=[gr.Text(label=\"Answer\")],\n",
    "                         flagging_mode=\"never\"\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44e27644-472c-4694-b33d-5429d3e3715a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* Running on public URL: https://3d6fd19a0d9491ccc7.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://3d6fd19a0d9491ccc7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2459547-4edb-4b1f-9635-bbe3a0c35eef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
